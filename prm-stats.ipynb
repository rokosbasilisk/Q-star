{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a6d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "from itertools import accumulate\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import gc\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "199ad856",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardModelDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, json_file,tokenizer):\n",
    "        self.data = [sample for sample in self.load_data_from_file(json_file) if len(sample[\"label\"][\"steps\"]) > 0]\n",
    "        \n",
    "        self.total_length = sum(len(sample[\"label\"][\"steps\"]) for sample in self.data)\n",
    "        \n",
    "        self.slots = list(accumulate([len(sample[\"label\"][\"steps\"]) for sample in self.data]))\n",
    "        self.ctx_target_pairs = []\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        def find_pos(numbers, x):\n",
    "            if x < numbers[0]:\n",
    "                return 0  # Insert at the beginning\n",
    "            elif x > numbers[-1]:\n",
    "                return len(numbers)  # Insert at the end\n",
    "            else:\n",
    "                return bisect_left(numbers, x)\n",
    "            \n",
    "        def tokenize_and_detokenize(sentence):\n",
    "            tokens = tokenizer.tokenize(sentence)\n",
    "            selected_tokens = tokens[:random.randint(0, len(tokens))]\n",
    "            detokenized_prefix = tokenizer.convert_tokens_to_string(selected_tokens)\n",
    "            return detokenized_prefix\n",
    "\n",
    "        \n",
    "        for idx in tqdm(range(self.total_length)):\n",
    "            slot_idx = find_pos(self.slots, idx)\n",
    "            sample_idx = self.slots[slot_idx] - idx \n",
    "            sample = self.data[sample_idx]\n",
    "\n",
    "            question = sample[\"question\"][\"problem\"]\n",
    "            steps = sample[\"label\"][\"steps\"][:sample_idx + 1]\n",
    "            context = question+\"[ANS]\"\n",
    "\n",
    "            targets = []\n",
    "\n",
    "            for step in steps[:-1]:\n",
    "                completion = random.choice(step[\"completions\"])\n",
    "                context += f\"  [SEP]{completion['text']} <[RATING]> {completion['rating']}\"\n",
    "\n",
    "            final_ctx = random.choice(steps[-1][\"completions\"])\n",
    "            \n",
    "            # randomly split the context as a prefix\n",
    "            rnd_ctx = tokenize_and_detokenizefinal_ctx['text'](final_ctx['text'])\n",
    "            context += f\"  [SEP]{rnd_ctx} <[RATING]>\"\n",
    "            target = ({-1: 0.0, 0: 0.5, 1: 1.0 }.get(final_ctx['rating'], 0.0)*idx)/self.total_length # trick to convert feedback to reward\n",
    "            self.ctx_target_pairs.append({\"context\": context, \"target\": target})\n",
    "\n",
    "\n",
    "    def load_data_from_file(self, json_file):\n",
    "        with open(json_file, 'r') as file:\n",
    "            data = [json.loads(line) for line in file]\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.ctx_target_pairs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7d1abbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 696998/696998 [00:01<00:00, 399580.15it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = RewardModelDataset(\"prmdata/train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "53f2c443",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89504cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
